{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 기초\n",
    "예측 문제의 최종 목표는 예측 오차를 최소화하는 예측 모형을 찾는 것.\n",
    "\n",
    "- 예측모형\n",
    "$$ \\hat y = g(x) = w^Tx $$\n",
    "\n",
    "\n",
    "- 모수 w를 입력하고 예측 오차를 출력하는 함수 $( e = \\left| \\;y-\\hat y\\;\\right| )$\n",
    "\n",
    "$$ \\text{모수} w \\;\\; \\xrightarrow{f} \\;\\; \\text{오차의 크기} e^Te  $$\n",
    "\n",
    "찾고자 하는 모수 $w$는 $e^Te$를 최소화하는 값. 이러한 문제를 최적화 문제라고 한다. \n",
    "*최대화의 경우, $-f$의 최소화를 구해 반전시키면 된다.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 문제\n",
    "최적화 문제는 함수 $f$ 값을 최소화하는 변수 $x*$를 찾는 것\n",
    "\n",
    "$$ x^* = \\arg \\min_{x} f(x) $$\n",
    "\n",
    "ex) objective function, cost function, loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그리드 서치와 수치적 최적화\n",
    "\n",
    "**grid search** : 가능한 $x$의 값을 여러개 넣어 그 중 가장 작은 값을 선택하는 방법. 가장 간단하지만 많은 계산이 필요하다. **최소** 횟수의 **시행착오(trial and error)**를 통해 $x^*$를 찾는 방법을 **수치적 최적화(numerical optimization)**라고 한다.\n",
    "\n",
    "수치적 최적화 방법은 다음 두 가지 알고리즘을 요구한다.\n",
    "- 현재 위치 $x_k$가 최적점인지 판단하는 알고리즘\n",
    "- 어떤 위치 $x_k$를 시도한뒤, 다음 번에 시도할 위치 $x_{k+1}$을 찾는 알고리즘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기 필요 조건\n",
    "\n",
    "현재 위치 $x$가 최소점인지 알아내는 알고리즘.\n",
    "어떤 독립 변수 값 $x^*$가 최소점이 되기 위해서는 기울기가 0, 즉, 도함수 $\\dfrac{df}{dx}$ 의 값이 0이 되어야한다. 이를 기울기 **필요 조건**이라 한다.\n",
    "\n",
    "- 단일 변수 함수의 경우\n",
    "\n",
    "$$ \\dfrac{df(x)}{dx} = 0 $$\n",
    "\n",
    "- 다변수 함수의 경우\n",
    "\n",
    "$$ \\dfrac{\\partial f(x_1, x_2, \\cdots, x_N)}{\\partial x_1} = 0 $$\n",
    "\n",
    "$$ \\dfrac{\\partial f(x_1, x_2, \\cdots, x_N)}{\\partial x_2} = 0 $$\n",
    "\n",
    "$$ \\vdots$$\n",
    "\n",
    "$$ \\dfrac{\\partial f(x_1, x_2, \\cdots, x_N)}{\\partial x_N} = 0 $$\n",
    "\n",
    "$$ \\rightarrow \\nabla f = 0 $$\n",
    "\n",
    "\n",
    "gradient vector를 $g$ 라는 기호로 간단하게 나타내기도 한다.\n",
    "\n",
    "기울기가 0이어도 local minima거나 최고점일 수 있다. 이 문제는 다른 방법으로 해결한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD방법\n",
    "Steepest Gradient Descent (SGD)방법은 현재 위치에서의 기울기 값 $g(x_k)$만을 이용하여 다음에 시도할 위치를 알아내는 방법이다.\n",
    "\n",
    "$$ x_{k+1} = x_k - \\mu\\nabla f(x_k) = x_k - \\mu g(x_k) $$\n",
    "\n",
    "현재 위치 $x_k$에서 기울기가 음수 $g(x_k) < 0$인 경우, 앞으로(우측으로) 진행하고 양수인 경우 뒤로 진행하여 점점 낮은 위치로 옮겨간다.\n",
    "\n",
    "$\\mu$를 스탭 사이즈(step size)라고 하며 사용자가 알맞게 조정해야한다. 스탭 사이즈가 너무 큰 경우 최저점을 찾지 못할 수 있고, 너무 작은 경우 시간이 오래걸린다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
