{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률론적 언어 모형\n",
    "m개의 단어 열(word sequence)이 주어졌을 때 문장으로써 성립될 확률을 출력함으로써 이 단어 열이 실제로 현실에서 사용될 수 있는 문장인지 판별하는 모형\n",
    "\n",
    "다음과 같이 계산\n",
    "$$\\begin{eqnarray}\n",
    "P(w_1, w_2, \\ldots, w_m) &=& P(w_1, w_2, \\ldots, w_{m-1}) \\cdot P(w_m\\;|\\; w_1, w_2, \\ldots, w_{m-1}) \\\\\n",
    "&=& P(w_1, w_2, \\ldots, w_{m-2}) \\cdot P(w_{m-1}\\;|\\; w_1, w_2, \\ldots, w_{m-2}) \\cdot P(w_m\\;|\\; w_1, w_2, \\ldots, w_{m-1}) \\\\\n",
    "&=& P(w_1) \\cdot P(w_2 \\;|\\; w_1) \\cdot  P(w_3 \\;|\\; w_1, w_2) P(w_4 \\;|\\; w_1, w_2, w_3) \\cdots P(w_m\\;|\\; w_1, w_2, \\ldots, w_{m-1})\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "\n",
    "1. $P(w_m\\;|\\; w_1, w_2, \\ldots, w_{m-1})$ 은 \n",
    "1. 지금까지 $ w_1, w_2, \\ldots, w_{m-1}$라는 단어 열 **(문맥, context)** 이 나왔을 때\n",
    "1. 다음 단어로 $w_m$이 나올 조건부 확률\n",
    "\n",
    "조건부 확률을 모형화하는 방법에 따라\n",
    "1. Unigram Model\n",
    "1. Bigram Model\n",
    "1. N-gram Model \n",
    "\n",
    "로 나뉘어 진다.\n",
    "\n",
    "## Unigram Model\n",
    "모든 단어의 활용이 서로 완전히 독립이라고 가정\n",
    "- 단어 열의 확률 = 각 단어 확률의 곱\n",
    "\n",
    "\n",
    "## Bigram Model (Markov Model)\n",
    "단어의 활용이 `바로 전 단어`에만 의존한다고 가정\n",
    "$$P(w_1, w_2, \\ldots, w_m) = P(w_1) \\prod_{i=2}^{m} P(w_{i}\\;|\\; w_{i-1})$$\n",
    "\n",
    "\n",
    "## N-gram Model\n",
    "바로 전 N개의 단어에 의존한다고 가정\n",
    "$$P(w_1, w_2, \\ldots, w_m) = P(w_1) \\prod_{i=n}^{m} P(w_{i}\\;|\\; w_{i-1}, \\ldots, w_{i-n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률 추정 방법\n",
    "- Bigram model\n",
    "\n",
    "    1. 모든 문장에 문장의 시작과 끝을 나타내는 특별 토큰을 추가. \n",
    "    1. 전체 문장의 확률은 다음과 같은 조건부 확률의 곱\n",
    "    \n",
    "    $$P(\\text{SS I am a boy SE}) = P(\\text{I}\\;|\\; \\text{SS}) \\cdot P(\\text{am}\\;|\\; \\text{I}) \\cdot P(\\text{a}\\;|\\; \\text{am}) \\cdot P(\\text{boy}\\;|\\; \\text{a}) \\cdot P(\\text{SE}\\;|\\; \\text{boy})$$\n",
    "    \n",
    "    1. 다음과 같이 추정\n",
    "    \n",
    "    $$P(w_{i}\\;|\\; w_{i-1}) = \\dfrac{C(w_{i}, w_{i-1})}{C(w_{i-1})} = \\dfrac{N_{real}}{N_{chance}}$$\n",
    "    \n",
    "    단어의 실제 등장 횟수 / 단어가 나올수 있는 기회(전체 유니그램이 나타나는 횟수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /home/mk/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "sentences = []\n",
    "for s in movie_reviews.sents():\n",
    "    s.insert(0, \"SS\")\n",
    "    s.append(\"SE\")\n",
    "    if len(s) > 4:\n",
    "        sentences.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SS', 'they', 'get', 'into', 'an', 'accident', '.', 'SE']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calculate_bigram(sentences):\n",
    "    bigram = {}\n",
    "    for s in sentences:\n",
    "        context = \"SS\"\n",
    "        for i, w in enumerate(s[1:]):\n",
    "            if context not in bigram:\n",
    "                bigram[context] = Counter()\n",
    "            if bigram[context][w] == 0:\n",
    "                bigram[context][w] = 1\n",
    "            bigram[context][w] += 1\n",
    "            context = w\n",
    "    for context in bigram.keys():\n",
    "        total = sum(bigram[context].values())\n",
    "        for w in bigram[context]:\n",
    "            bigram[context][w] /= total\n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = calculate_bigram(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 처음에 올 수 있는 단어들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.11231263830320237),\n",
       " ('it', 0.043575076893101194),\n",
       " ('i', 0.03379121261464379),\n",
       " ('but', 0.02523207103391647),\n",
       " ('and', 0.024160438673402642),\n",
       " ('he', 0.023269731256871668),\n",
       " ('in', 0.023102723616272112),\n",
       " ('this', 0.022963550582439148),\n",
       " ('there', 0.0180507424881355),\n",
       " ('as', 0.013249272820898222)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[\"SS\"].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 0.14362771020624007),\n",
       " ('was', 0.053622421998942356),\n",
       " ('can', 0.03722897937599154),\n",
       " ('have', 0.035007932310946586),\n",
       " ('don', 0.02929666842940243),\n",
       " ('think', 0.028027498677948175),\n",
       " ('had', 0.02147012162876785),\n",
       " ('would', 0.021152829190904283),\n",
       " ('know', 0.018826017979904814),\n",
       " ('didn', 0.01850872554204125)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[\"i\"].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'\"': 0.02922949299760894,\n",
       "         \"'\": 0.0010735373054213634,\n",
       "         \"''\": 6.506286699523415e-05,\n",
       "         ')': 0.00821418695814831,\n",
       "         'SE': 0.9612387969875893,\n",
       "         ']': 0.0001789228842368939})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[\".\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'he' 단어 뒤에 'is'가 나올 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09349147812219676"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[\"he\"][\"is\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장의 확률 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_score(s):\n",
    "    p = 0.0\n",
    "    for i in range(len(s) - 1):\n",
    "        c = s[i]\n",
    "        w = s[i + 1]\n",
    "        p += np.log(bigram[c][w] + np.finfo(float).eps)\n",
    "    return np.exp(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.288036438066686e-08"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = [\"i\", \"am\", \"a\", \"boy\", \".\"]\n",
    "sentence_score(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9683389110380156e-38"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = [\"i\", \"is\", \"boy\", \"a\", \".\"]\n",
    "sentence_score(test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    c = \"SS\"\n",
    "    sentence = []\n",
    "    while True:\n",
    "        if c not in bigram:\n",
    "            break\n",
    "        words, probs = zip(*[(k, v) for k, v in bigram[c].items()])\n",
    "        idx = np.argmax(np.random.multinomial(1, probs, (1,)))\n",
    "        w = words[idx]\n",
    "        \n",
    "        if w == \"SE\":\n",
    "            break\n",
    "        elif w in [\"i\", \"ii\", \"iii\"]:\n",
    "            w2 = w.upper()\n",
    "        elif w in [\"mr\", \"luc\", \"i\", \"robin\", \"williams\", \"cindy\", \"crawford\"]:\n",
    "            w2 = w.title()\n",
    "        else:\n",
    "            w2 = w\n",
    "        \n",
    "        if c == \"SS\":\n",
    "            sentence.append(w2.title())\n",
    "        elif c in [\"`\", \"\\\"\", \"'\", \"(\"]:\n",
    "            sentence.append(w2)\n",
    "        elif w in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
    "            sentence.append(w2)\n",
    "        else:\n",
    "            sentence.append(\" \" + w2)\n",
    "            \n",
    "        c = w\n",
    "    return \"\".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alexandre dumas may suspect he at being can be honest here goes awol, but he trusts affleck - see this documentary.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "활용\n",
    "- spell correction 철자, 문법 교정\n",
    "- speech recognition 음성 인식 \n",
    "- machine translation 자동 번역\n",
    "- Summarization 자동 요약\n",
    "- Question-Answering 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
